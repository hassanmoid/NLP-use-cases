{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2LSRQWgJuirZ",
        "pWXRVnE0uxrA",
        "cO_vWM9hw7QA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGV4SEYFtarD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import numpy as np                          # library for scientific computing and matrix operations\n",
        "import nltk                                 # NLP toolbox\n",
        "from os import getcwd\n",
        "import pandas as pd                         # Library for Dataframes \n",
        "from nltk.corpus import twitter_samples     # loading twitter_samples from nltk library\n",
        "import matplotlib.pyplot as plt             # Library for visualization\n",
        "\n",
        "#from utils import process_tweet, build_freqs # Our functions for NLP"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHq8wdkxt2t-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0a7710ee-02d6-48db-8117-b2c4595e9224"
      },
      "source": [
        "# downloads sample twitter dataset. uncomment the line below if running on a local machine.\n",
        "nltk.download('twitter_samples')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4QOj7V3uNQ7",
        "colab_type": "text"
      },
      "source": [
        "We can load the text fields of the positive and negative tweets by using the module's `strings()` method like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TvQYwe8t6tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uelUUbTkuXqB",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll print a report with the number of positive and negative tweets. It is also essential to know the data structure of the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6XceHMIt9Ss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c6a6db5f-9357-4ed3-94db-b46246ac0bfd"
      },
      "source": [
        "print('Number of positive tweets: ', len(all_positive_tweets))\n",
        "print('Number of negative tweets: ', len(all_negative_tweets))\n",
        "\n",
        "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
        "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive tweets:  5000\n",
            "Number of negative tweets:  5000\n",
            "\n",
            "The type of all_positive_tweets is:  <class 'list'>\n",
            "The type of a tweet entry is:  <class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDtFfxrIueKB",
        "colab_type": "text"
      },
      "source": [
        "We can make a more visually appealing report by using Matplotlib's pyplot library. Let us see how to create a pie chart to show the same information as above. This simple snippet will serve us in future visualizations of this kind of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAi4_MhLt_D-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "2a675983-a1df-469d-d67b-43c50dcc1a75"
      },
      "source": [
        "# Declare a figure with a custom size\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "\n",
        "# labels for the two classes\n",
        "labels = 'Positives', 'Negative'\n",
        "\n",
        "# Sizes for each slide\n",
        "sizes = [len(all_positive_tweets), len(all_negative_tweets)] \n",
        "\n",
        "# Declare pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
        "plt.pie(sizes, labels=labels, autopct='%1.1f%%',\n",
        "        shadow=True, startangle=90)\n",
        "\n",
        "# Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.axis('equal')  \n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEeCAYAAACNLn6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yc1YHu8d+ZGbWR5HHvNjK2wIDBNk2UUJYWSgIhoW52YVOXNG5ustk42SyZhFyWbLLpIaElJISAgSVgMGASQ+gWxhWDEbLBBdxtWW0kTTv3j/eVLXdZlnRm5n2+n898JI00mmdUnjlzzluMtRYREQmOkOsAIiLSv1T8IiIBo+IXEQkYFb+ISMCo+EVEAkbFLyISMCp+EZGAUfGLiASMil9EJGBU/CIiAaPiFxEJGBW/iEjAqPhFRAJGxS8iEjAqfhGRgIm4DiByKKpmzB4AjAJG+2+7vj8aGAQU4f2td76N/K7ovxecE158ApAGUv7bNJAEtgLrgXW7vfXejze29tfjE+kLKn7JeVUzZk8ETgCOB6rYteTLe/I9i0hXACN7FCgea2bXJ4OVwELgdeKNa3v0PUX6kYpfckqXku+8HI83au9VDS3tE4j1+OaVwJH+ZVfx2GZgQZeLngwk56j4xZmqGbMPA2ro45LfK2tNH33nYcCF/sWz55PBPOKN6/vo/kUOSMUv/aZqxuwQXtFf6l+OdpXFGJPtx7vb/cnAEo8tBB4HZhFvXNSPWURU/NK3qmbMjgLn4xX9JcAIt4lygmHnq5w48dhaOp8E4DnijUmX4aTwqfil11XNmD0K+Kh/ORcoc5so540DvuhfmonH5uA9CTxJvHGr02RSkFT80iuqZsweCnwKuBI4EW9UKwevErjCv2SIx14BZgL3Em9scppMCoaKXw5J1YzZpwJftNZeaYwpcZ2nwISBM/zLrcRj9wG3EW9c6jaW5DsVvxw0f97+k9baLxhjpgMYowF+H6sA/hX4V+Kxl4HbgIe1HiA9oeKXbquaMftIvNH99caYmMremdP9y0+Jx+4Gfku8cY3jTJJHVPyyX1UzZkeAy/AWHs8Bje5zyHDgW8C/E489ifcqYA7xRus2luQ6Fb/slV/4n7XW/ocxZqzrPLJfYXZuRVVPPBYH7tcTgOyLjs4pu6iaMdtUzZh9tc1m3wZ+o9LPO9XAfcBC4rELD/TFEkwqftmhasbsC2wmvRh4wIRCE13nkUMyDXiKeOw54rEa12Ekt2iqR6iaMfskm0n/2IQjZ5qw/iQKzNnAPOKxR4FvE29c7jiP5AD9lwdY1YzZR9pM+ocmHLlMhV/wPgZ8lHjsj8B3dcTQYNN/ewBVzZg9xmYzN2NC15twRNN9wRHG27v6WuKxXwO3EG/c5jiTOKB/+gCpmjHbHPaNx75qbXaFCYU/ZYzR7z+YSoGv420B9E+uw0j/0z9+QIz/t79MyqbaXzfhyE+NCZW6ziM5YTBwL/HYY8RjPTsbmeQlFX+Bq5ox24y78c/fMaHwW6Gi0uNd55GcdCnwlkb/waHiL2DjvzrziGxH65JwNHazCYWLXOeRnDYIjf4DQ8VfgHaM8ovLloVKyo91nUfyikb/AaDiLzAa5Usv0Oi/wKn4C4RG+dIHNPovUCr+AjD6M7fFMonGlzTKlz7QOfq/k3is2HUY6R0q/jw34qrv1YQrh9SFo7HTXGeRgvZZYC7x2DDXQeTQqfjzVLS6xoy4+uYvlow79vlwacUI13kkED4EvE48Ns11EDk0Kv48FK2uCcdOuer20sOm/SpUVKLz3Ep/Gg+8TDx2hesg0nMq/jwz8KzrYgPP+pfnS8ZM/pwJhXQqLHEhCjxIPPZ94jH9DeYhFX8eGfqRrx1dMeW8pcVDx5/uOosEngH+E3iEeKzCdRg5OCr+PDH8EzddHq0+ZV6kcsh411lEuvgY8ArxWJXrINJ9Kv4cF62uMSOuvSVedvgJD4ZKyitd5xHZi2OB+cRjZ7kOIt2j4s9h0eqa4soTPnpX6fjjbjLhiM6dILlsKDCHeOwjroPIgan4c1S0umZQ5fSLHyo9bNqnjTFaQJN8UII35/8J10Fk/1T8OShaXTO8cvrFj5QdfuKl6nzJM0XATOKxf3QdRPZNxZ9jotU1oypPuPSRssNPPNt1FpEeCuMd5uHTroPI3qn4c0i0umZs5QmXPlJWNU2ba0q+CwF3EY991nUQ2ZOKP0dEq2vGV06/eGZZ1bRTXGcR6SUGuJ147J9dB5FdqfhzQLS6pqriuAvuKzv8RB1oTQpNCPg98dhVroPITip+x6LVNePKp5xzT9mkmg+5ziLSR8LAfcRjl7kOIh4Vv0PR6prR0aPOvDt6xOlnaesdKXARvOP7fNh1EFHxOxOtrhlZMm7Kz8snn3muSl8Cohh4iHjsaNdBgk7F70C0umZYZOComyunX3KJCYX0O5AgqQRmEY8Ndh0kyFQ6/SxaXVNuisu+GTv1ystDRSVlrvOIODARb9pHhyFxRMXfj6LVNWEwn4udevXHw9GBQ1znEXHoXOAnrkMElYq/n0SrawzwscrjL7m+eOj4Ca7ziOSArxCPfcZ1iCBS8fefmrKJJ325tGq6zlcqstNtxGPaU72fqfj7QbS6ZkLRsAnfrDj2/NO1BY/ILorxjug5znWQIFHx97Fodc2gUHTgN2M1nzjHhCNFrvOI5KDhwGPEY1HXQYJCxd+HotU1JYQjXxl4+rWXhkqiA1znEclh04Hfuw4RFCr+PuIv5n5ywIkfuzoyYNgo13lE8sBVxGPfcB0iCFT8fef8krHHXF0y5ijtpSjSfTcTjx3jOkShU/H3gWh1zdGmqPS6ymkXnazFXJGDUoJ3NM+w6yCFTMXfy6LVNZXADQNOvvyYUEl0oOs8InnoJODfXYcoZCr+XuTP619dMm7KxOIRk7S9vkjPfVdTPn1Hxd+7jjVFpedUTrvwNE3xiBwSTfn0IRV/L/GneD474OTLjwoVa4pHpBdoyqePqPh7gaZ4RPqMpnz6gIq/d2iKR6RvaMqnD6j4D5GmeET6nKZ8epmK/xDsmOIZe8zhmuIR6VPf1Skbe4+K/9AcC5xZcdz5J2iKR6RPlQA/ch2iUKj4e6hziic6+YzB4bIBI13nEQmAi4nHznQdohCo+HvuI4TCFdFJNae5DiISILe6DlAIVPw9EK2uGQGcX3HcBSNDJdFBrvOIBMipxGOXuQ6R71T8PXOZKSqldPxxZ7gOIhJAt2jzzkOj4j9I0eqa8cCpldMuqgoVlVS4ziMSQEcD17kOkc9U/AfB33zzilBZzJaMOUpz+yLuxInHSlyHyFcq/oNzBDC1cvpFk004oj86EXfGA19yHSJfqfi7KVpdEwKuisSGZ4tHTDzJdR4R4dvEYzqXdQ+o+LvvWGBixbSLpppQOOI6jIgwBNA5entAxd8N0eqaCHBt0dDxFA0Zr0MziOSO/0s8Ntx1iHyj4u+ek4CR5UeddYzRsRlEckk58HnXIfKNiv8AotU1JcBVpqR8e9GQcce5ziMie/i8tus/OCr+AzsBGFh+1JnVJhwpdh1GRPYwDvio6xD5RMW/H/52+xcDDSVjJp/oOo+I7NMXXQfIJyr+/TscGFNaNX1QuLRSC0giues84rFq1yHyhYp///4B6CibcLy22xfJbQb4gusQ+ULFvw/R6poYcGq4cmgiMmjUUa7ziMgB/QvxWJnrEPlAxb9vJwOm/KgzpxkT0s9JJPcNAq51HSIfqND2IlpdEwYuxoS2Fo+YdILrPCLSbVrk7QYV/94dBQyMHnHauFBxqY4FIpI/TiAeO9l1iFyn4t+7C4BE6fjjtKgrkn806j8AFf9u/NMqHhuJjWgPVw453HUeETloV2mRd/9U/Hs6HciWVk0/UoflEclLZcD5rkPkMhV/F9HqmiLgPGBT8bCqI1znEZEe0yEc9kPFv6vDgVJTHM2GK4dMcB1GRHrsI8Rjesm+Dyr+XU0FMmUTjp+ok62I5LWRePviyF6o+H3+AdlOBbYVj5x0pOs8InLILnUdIFep+HcaA8Qwpr1o4EjN74vkPxX/Pqj4dzoaoHT8cWNNpDjqOoyIHLIpxGNaq9sLFf9OpwHbS0ZP1jSPSOHQqH8vVPxAtLpmEDAeaC4aPFbFL1I4VPx7oeL3HAFQNPSwQaHS8qGuw4hIrzmDeCzmOkSuUfF7TsE7No8WdUUKSxFwkesQuSbwxR+trikFpgANRYNHayFIpPCc7TpArgl88QOTgDCQCUVjo1yHEZFep3Nq7EbFD8cB6fCAYRWhotJK12FEpNcdSzxW5DpELlHxw2SgqXjEJI32RQpTCd50rvgCXfzR6ppivD12W4sGjx7tOo+I9BlN93QR6OIHOkf5NlI5VMUvUrhU/F2o+MEAaGFXpKCp+LsIevFPAlJa2BUpeMdpgXenoBf/EUCzFnZFCp4WeLsIbPFrYVckcDTd4wts8aOFXZGgUfH7gl78WtgVCQ4Vvy/IxT8JSIXKKku0sCsSCEe7DpArglz8RwDNkcphKn2RYCgnHhvgOkQuCGTxR6trivAXdsMVg1X8IsGh9TwCWvxA57O+DZUNUPGLBIfW8whu8VcCFiBUVqniFwkOjfgJdvF7W/SUlFc4ziIi/UcjflT8hEqiGvGLBIdG/AS3+GP4Uz1Gm3KKBIlG/AS3+IcDSQBtwy8SKBrxE9ziH4pf/KaoRHP8IsGhET/BLf7BQEeorLLEhMI6VKtIcKj4CW7xDwKSYe21KxI0FcRjgf+/D1zx+4djLgPS4Wis3HUeEel3I10HcC1wxQ9UAFkAEynWNI9I8JS6DuBa5EBfYIzJAG/4X7scuN5am+juHRhjRgO/sNZeYYyZBoy21j7pf+5S4Ghr7a09St8zO/baNaFQzj3xvf+bTxMqLoNQCBMKM+r6n5Fpa2bLYz8k3bSRyIARDP3YDMKle65Jt7wxl8ZXHwAgduo1VBx7LjadYtMjN5Np3kLl9EuoPP4SALY+/Usqpl1EychJ/fr4xL2qnzVTWWIIG4iE4PXPV7CtzXL1wwlWbbdUDTQ8eEWUQWVmj9v+YXGSH7yYBOA7ZxRz/bRiOtKWyx5I8H6T5YsnFfPFk4oB+PzjbdxwYjHHjwr36+PrhgP23t4YYyzwE2vt1/2P/w2osNbGezEbxphvW2tv6fLxK9ba03rzPrpTfG3W2mnW2il4W8LccDB3YK1dZ629wv9wGnBxl8/N6ufSB2+ax2PCOVf8ACOuvYXRn/olo67/GQBN8x6itGoqYz5/J6VVU2ma99Aet8m0NdP48p8Z+c8/YeR1P6Xx5T+TaW+h7b2FlIw9mlGf/hUtbz4LQHLTu9hsVqUfYM9dH2XxDRW8/nlvAHHrSx2cOyFC/VcqOHdChFtf6tjjNtvaLN97voPaz5bz2mfL+d7zHTS0WeasTPOh8RGWfqGce5emAFiyIUMmSy6WPkBPX+l3AB83xgztzTB78e2uH/R26cPBT/W8CEwyxgw2xjxqjFlqjJlnjDkOwBhzljFmsX9ZZIypNMZUGWOWGWOKge8DV/ufv9oY8y/GmF8ZY2LGmNXGmJD/fcqNMWuNMUXGmInGmKeNMQuMMS8aYyb7X3Ol/32XGGNe6NFjzsER/94kVtRSPuVcAMqnnEuift4eX9P+3kJKq6YTLqskXFpBadV02t9dgAmFsakOyGT81zmw/cU/MfCMf+rPhyA57rG6NNdP9frw+qlFPFqX3uNr5qxIc/7hEQaXGQaVGc4/PMLTK9IUhSCRsqQyYP2/sf98roObzynpz4dwMHo04gfSwB3A/939E8aYYcaY/zXGzPcvp3e5/q/GmDeNMXf5PTfU/9yjfq+9aYz5vH/drUCZ35H3+de1+G8fMMZc0uU+7zHGXGGMCRtjfuTf71JjzL8e6IF0u/iMMRHgIrxpn+8Bi6y1x+E9O/3R/7J/A75krZ0GnAG0dd7eWpsEbgJm+q8gZnb5XCOwGDjLv+ojwBxrbQrvB/0Va+0J/ve/zf+am4APW2unApd293H4j9l4jykHR/zGsOnBm1h/z/+hefHTAGRatxOpGAxAuHwQmdbte9ws3byV8ICdA5Fw5RDSzVspnTCddOMm1t/7dQac+FES9bUUj5hIpHJI/zweyTnGwAX3JjjhjhbuWOBN22xsyTKq0vt3GFlh2NiS3eN2HzRnGRfb+S8zdkCID5qznD8xwqrtWU65u5Uba4qZVZfi+FEhRlfm3r+Xr6fFD/Br4JPGmNhu1/8c+Km19iTgE8Bd/vXfBZ611h4DPAyM73KbT/u9diJwozFmiLV2BjtnWT65233MBK4C8AfS5wKzgc8Ajf59nwR8zhgzYX8Pojs/gDJjzGL//ReBu4Fa/8FhrX3WGDPEGDMAeBn4if9M9Yi19n1j9pwn3IeZwNXAc8A1wG3GmArgNOChLt+ncxjxMnCPMeZB4JHu3gle8XvjEv8VRi4Z+ckfEqkcSqZ1OxtnfoeiIWN3+bwxhm7/RAETCjPs0m8AYDNpNj54E8M//h22zb2TTNNmyqecS7S6phcfgeS6lz5VzpgBITa1Zjn/3gSTh+76b2CMofv/thAJGf78iSgAqYzlw39K8Ng1Ub42p501jVmum1rEpUfm1HYUPQ5jrW0yxvwRuJEuA1vgPODoLj01wO+vDwGX+7d92hjT0OU2NxpjLvffHwdUA1v3c/dPAT83xpQAFwIvWGvbjDEXAMcZYzqn1GP+93pvX9/oYOb4p1lrv+KP3PfKn6//LN48+sud0zLdNAu40BgzGO/cmM/6+bZ3uf9p1tqj/Pu6AfgO3g9sgTGmu0PYHSP+XBSp9Ebt4fKBRI84lY517xAuH0i6ZRsA6ZZthMoH7uV2Q8g0bdnxcaZ56x6j+uZFs6mYcg4d6+oIlZQz9LJv0jT/L334aCQXjRng/dsPLw9x+eQIr32QYURFiPXN3ih/fXOW4eV7VsOYyhBrG3e+Eni/KcuY3Ub1t81Pct3UIua9nyFWYph5RRn/8+o+K8MVe4i3/xneKLvr5uAh4JQuPTXGWtuyr29gjDkb78niVH/WYhEH2NrIWtsO/B34MN4guXPWxODNinTe9wRr7TP7+149HfG+CHyyywPY4j8TTrTWvmGt/SEwH9i9+JvxtqrZg/9Dmo/3kukJa23GWtsEvGeMudK/L2OMmeq/P9FaW2utvQnYjPcE0B07V5tsds/Xsw5lk+1kOxI73m9/bxHFww4jOqmG1mVzAWhdNpfopD1H6KUTjqdt1SIy7S3eou6qRZROOH7H5zPtLbStmE/5lHOw6Q7v9b4x3vsSGK1JS3OH3fH+MyszTBke5tIjIvxhibcw+4clKS47cs/JgA9PivDMu2ka2iwNbZZn3k3z4Uk7v66hzfJEfZrrphaRSFlC3p8YbalD7dlelzqUG1trtwEP4pV/p2eAr3R+4G/BCN7MROf0zAV4O4+CNypvsNYm/AHyKV3zGWP29apkJvApvKn0p/3r5gBf6LyNMeYIY8x+91Hq6VxXHPidMWYpkACu96//qjHmH/C2k38T76VJ112knwNm+FNH/7WX7zsTeAg4u8t1nwR+Y4z5Dt5LtAeAJcCPjDHVeM92c/3rusP4F2yOFX8msZ3Nj/zA+yCbpfzosyg7/ASKR1Wz5bFbaVn6DJEBwxl62QwAOtbX07L4KYZcdCPhskoGnnY1G/7grTsNPO0awmU7n2MbX76f2GlXYUyIsgnH07xwNuvv/jIV0y/q98cp7mxstVw+0xtcpLPwj1OKuHBShJNGh7jq4TbuXpTisJjhwSu9qZvX12X47etJ7rq0jMFlhv88s4ST7vQGsjedWcLgLpt8fv/5Dv7jjBJCxvDhSRF+PT/Bsb9JccMJxf3/QPdvz5Xrg/c/wJe7fHwj8Gu/EyPAC3hbQH4PuN8Y88/Aq8AGvAHw08ANxpjlQB3QdYuNO4ClxpiFe5nnfwa4F3isy+zLXUAVsNB4c02bgY/tL7yxNueejftUtLrmeOBLwNrokR+aXDHlnKtdZ5L+98uOm1Z/NLbiMNc5xImTiTfO74878ufjM9batDHmVOA3/sYvTh3K6na+2jHKt9lMxmUQEXGiN0b83TUeeNDfVD0JfK4f73ufAl382ExOTfWISL84pDn+g2GtrQem99f9dVfObc7YD3aO+FMd/fYHICI5o9V1ANeCWvwWINPS0Ow4i4j0v/WuA7gWxOLfMa+fbt68z+1sRaQgbSfe2O46hGtBLP6dh5FItqVsJqUN2UWCY53rALkgiMXfTJc9d20qqekekeAI/DQPBLf4dzzubKpdxS8SHBrxE8DiT9TXpvFW9YsAbLJN8/wiwaERPwEsfl8DUAyQTSY04hcJDo34CW7xb6Wz+NtbVfwiwaERP8Et/i34x/XPtjep+EWCQyN+glv8m/FH/JlEk+b4RYJDI36CW/yNne9kWrZpxC8SHBrxE9zib8Y/Zk+6aVNz0A5NLRJQDcQb2w78ZYUvyMUP+HvvJtu2uQwjIv1iqesAuSKoxd9Cl713M60NevknUvgWuA6QK4Ja/E14R+gMAaSbNmvBR6Twve46QK4IZPH7e++uAcoBUts+0IhfpPBpxO8LZPH76oBKgOSGd9ZrgVekoDUB9a5D5IogF/+7QBgg29bcoQVekYK2iHijRne+IBf/OvwzcYEWeEUKnKZ5ughy8W/032qBV6Twqfi7CGzxa4FXJFBU/F0Etvh9WuAVKXzNwDuuQ+SSoBe/FnhFCp8WdncT9OLXAq9I4dOOW7sJevHvssCb2rr2XYdZRKRv/M11gFwT6OLffYG37b0F71hN9IsUkhbgWdchck2gi9/3FjAAINO8tTWbaPzAcR4R6T3PEG/scB0i16j44Q26/BxSW9fUOcwiIr1rlusAuUjF723ZkwYiAO1rlqn4RQpDBpjtOkQuCnzxJ+prU8BCYDBAcuOKzdmORIPbVCLSC14l3rjFdYhcFPji980HSjs/SDWs06hfJP9pmmcfVPyezr36DEByfZ328hPJf4+7DpCrVPxAor62Be9Y3QMB2lYtXm0zqXa3qUTkELxDvPFt1yFylYp/p1fwj9tDNpNNN25a4TaOiBwCjfb3Q8W/09t0OQF7cuNKzfOL5C/N7++Hin+nTf6lcy/eepvNZtxGEpEe2AK87DpELlPx+xL1tRbvj2UQeEfrTG9f95bbVCLSA/cQb9SgbT9U/LtaRpfpnrZ3F8x3mEVEDpJ/rK3fuM6R61T8u1qNd1CnMoD21UvWZtqaNu7/JiKSK4wxc4g36ii7B6Di7yJRX5sBngKGdV7X8cHbGvWL5I/bXAfIByr+PdXinZwlBNC6/IWlNpPW0f1Ecpy1djU6Nk+3qPh3k6ivbQBeA4YD2GQildqyeonbVCJyIMaY24k3Zl3nyAcq/r17Fijp/CDxzqua7hHJYdbaJHCX6xz5QsW/dyuBDfh78iY3vbsl3bx1ldNEIrJPxpiHiTdudp0jX6j49yJRX5vFmysc3Hld+9o3NOoXyV1a1D0IKv59WwikgCKARN3Lb2dTHS1uI4nI7qy1S4g3ak/dg6Di34dEfW0C+Dv+Ii/ZTDa5ceUCl5lEZE/GGO2wdZBU/Pv3Av4pGQFa33puvs2kkw7ziEgX1toNwL2uc+QbFf/+fQCswJ/rzzRvbe1Y/848t5FEpJMx5nvEGxOuc+QbFf9++AduewoY0Hldy5I5r9h0Un9oIo6ls/Y9tAlnj6j4D2wpsB6IAWTbmzva1775ottIIhIJmW8Rb0y7zpGPVPwHkKivTQMP0GXTzpalc+Znk22N7lKJBFsqY5cCD7rOka9U/N3zBt5c/xAAm05m2lct+rvTRCIBVhQ2/0a80brOka9U/N3g79A1E2+u3wC0LJu7JNPeoj0FRfpZKmOfJ974V9c58pmKv/vqgSV0btdvrW1bUTvXaSKRACoKm2+4zpDvVPzd5G/h8zDeSVpCAIm6l+syrQ1rnQYTCZBUxj5KvFGHTzlEKv6DkKivXYN3Xt6Rnde1Ln/xb+4SiQSHtTZTFDbfdJ2jEKj4D94svL15wwDtqxevSTduqncbSaTwZSx/IN74juschUDFf5AS9bUbgb8Cozqva1781NM2m9H2xCJ9JJ212yMh8y3XOQqFir9nnsI7PWMxQGrL6m3ta5Y+6zaSSOHKZPkS8cZNrnMUChV/DyTqa7fjTfmM7ryueeET8zItWugV6W3b2+3ckh80/dl1jkKi4u+5vwIbgUEAWGubFsx6VFM+Ir2nI21bSyP8o+schUbF30OJ+tp24E5gIP5Cr6Z8RHpXY4e9sfQHTZri6WUq/kOQqK9dATwBjO28TlM+Ir1jW5t9bviPmn/nOkchUvEfuseBTWjKR6TXdKRta7SIa1znKFQq/kOkKR+R3qcpnr6l4u8FmvIR6T2a4ul7Kv7eoykfkUOkKZ7+oeLvJfua8ml7b+Ecp8FE8oS1loZ2e4OmePqeir8X7W3Kp2XxU68nN69e6C6VSH5Y3WjvHvnj5j+5zhEEKv7e1znls+NUjY0v//nJTMu2Ne4iieS21duzS15dm/mc6xxBoeLvZf6Uz2+Acrxj92Mzqcz2V+5/UOfpFdnTlkR2yxPvpC+59n8TOpViP1Hx94FEfe0q4Ha8I3iGATLNW1ubFsx6wGYzKZfZRHJJImXbn3svc/mXnmz7wHWWIFHx95FEfe1rwGPAePzz9CbX1W1offvFR50GE8kRmazNvrQm89UrH0q85DpL0Kj4+9ajwAK6LPYmlr/wVvsHy19wF0kkN9R+kLnzV68l73CdI4hU/H0oUV+bAe7GO4rnsM7rm+Y99Fxq+4a3nQUTceytzZmXbn0p+aVZdSnN6zug4u9jifraVuDneD/rys7rt790318y7c3aXlkC54Om7JpH305/ZFZdKuM6S1Cp+PuBf7rGXwBD8M/aZTtak02vPnS/TSfbnIYT6UeN7bZ57nvpi749t11buDmk4u8nifra5cC9ePP9IYDUtve3Ny184j6bSSedhhPpB61J2/7MyvQ11/2l7S3XWYJOxd+/ngXm4m3pA0DH2mUfNC968j5t5imFLJGyHfcvS335yocST7rOIir+fpWor7XA/UAdMKbz+vbVi0ORULMAAAqgSURBVNe0LJlzvw7oJoWoPW2Tdy1M3jKrLq0jbuYIFX8/S9TXJoFfAevwdvACoO3d199rWTb3QZvNasFLCkZH2qbuWpj8xd/ezfyXtuDJHSp+BxL1tc3AT4AtwMjO69vq59W3vvXcQ9Zms87CifSSZMamf7849dtnVmb+Y1ZdSlOZOUTF70iivrYR+DHQCAzfcX3dy3Wty+bO1Mhf8llH2iZ/+3ryt0/Wp78xqy6ljRdyjIrfoUR9bQPw30CCruX/zqvvtCyd82ct+Eo+akvZjl/UJu/427uZf59Vl+pwnUf2pOJ3LFFfu5W9lH/byvnvNi96Upt6Sl5JpGz7T+cl73hxTeabs+pS2kclR6n4c0CivnYTcCvQQpc5//ZVi1Y3L3z8XpvRqElyX0vStv34lY5fz3s/M2NWXSrhOo/sm4o/RyTqa7fglf82umzt077mjfcbX33w7mxHosFZOJED2NCS3fb95zt+/Pq67HdU+rlPxZ9DEvW12/CmfTYBozuvT25cuXnbs3fdmW7e8p6zcCL78OamzKpvPNN+y9tbsv9vVl2q3XUeOTAVf45J1NduB34EfECXY/lnE9vbtv3t9j91bFz5mst8Ip2stTy9IrX4W3M7ftTYwS+0kJs/VPw5KFFf24Q38p8PTAAiAGQz2caX7nsqUT/vcW3uKS6lMjZ5+4LU32+bn/oBcLu2088vEdcBZO8S9bVt0eqa24H3gSvwjumfAGhZ+szCdOPGLRXTLroqFCkud5lTgqex3Tb998sdc9/YlL11Vl1Kr0DzkEb8OSxRX5tN1Nc+jnc8/0HA4M7Pta9esmb7C3+8M9PWtMFZQAmc1duz677+TPv9b2zKfl2ln79U/HkgUV+7EPg+kKTLom+6YV3jtr/d/rtUwzod5lb63Lz3029/bU777Zta7bdm1aW0oUEeU/HniUR97VrgZmAlUIX/u7PJtlTDs3c91L522XPWWh0ES3pdJmszM5el5t3yYvJHqSw/nFWX0qbFeU7Fn0f84/v8BPgbXvmXdH6u6bVHXmheMOuebEfrNkfxpABtas1uvOm5jtn3vZG6Cfi9ttwpDEaDxPwTra4xwFnA9UAD0NT5OVNUGhlw8sfPLR4xscYYY1xlzHW/7Lhp9UdjKw5znSNXZbI289yqzOu3zU8uSWf5xay61JuuM0nvUfHnsWh1zZHAl4FSvOP77/hllh42dXzFseddFiopH7yv2weZin/fNrdmN/xsXrL2jU3Zt4BfzqpLrXedSXqXij/PRatrYsC1wGl4m3y2dn5Oo/99U/HvKZO12b+vyrz26/nJ+nSWx4HHtSduYVLxFwB/6mc68BmgmL2O/s+/LFQS1ejfp+Lf1ZaEN8pfujFbB9wxqy610nUm6Tsq/gKi0X/3qfg9GuUHk4q/wHRr9D/lvEtDpeVDHEXMCSp+2NyaXf/z2uRrGuUHj4q/QO1v9E8oHKo49vzppYcdd1aoqLTSUUSnglz8TR224bG3U7UPv5XeZOEJNMoPHBV/ATvQ6N8UlUYqp154SsnYo0434aJSRzGdCGLxJ1K25dn30i/+flFqUyrLRjTKDywVfwD4o/9rgFPxDvS2qevnQ9FYaeXUCz9UPHJSjQmFA3HgviAVfzJjO15Zm3nljgXJVS3eiTyfBJ7QKD+4VPwBEq2uORzvSJ9H4+30tctevpHYyMqKqRecXTT0sOmFvgAchOJPZ2160frs/N++nnx7c8Ia4BVg1qy61EbX2cQtFX/A+NM/R+G9AjgM2EqXPX8BioZNGFJx7HnnFg0adZSDiP2ikIs/a61dvjm7+PYFySWrtlsDLAUenlWXWuM6m+QGFX9ARatrQnjz/9cAw/Cmf3Y5V2rJ2GNGl08+4+zwgGGTCu0VQCEWfyZrs+82ZJffszi14I1NWYAVwEygflZdSv/osoOKP+Ci1TVFwCnAVUAFsAHY5UBcRYPHDoweefqJxcMnTDeR4qiDmL2ukIq/NWmbF67PLHhgWWr52iYbxfsd3g+8MasulXUcT3KQil8AiFbXlOEd+O1jQBHeJqDJrl9jIsXh6OQzjikde8xJ4fKBYx3E7DX5XvzWWj5otu/9fVV6/l+Wp9eksgwDtuON8OfPqkulHUeUHKbil11Eq2sqgfOAC/AO/taIVyi7KBk9eWTZpJqTioaMPdaEwkX9HPOQ5Wvxd6Rt+5ubs0seWZ56fenGrAGieL+fJ4CXdNhk6Q4Vv+xVtLqmBJgKXAKMB1J4rwJ2Ocl7qKyypPyos6aVjDrypHzaGzjfin9LIrvhlbWZ+Q8sS73dkmQw3rk03gSeAZZrhC8HQ8Uv++VvBXQYcDZwOhDG2xKodfevLZ1wQlXp2KOPiQwadUSoqHRAvwY9SPlQ/E0dtqF+a7buuVXpZS+szrQCMaAd70Q8L2mzTOkpFb90mz8NdBJwMTAEaAO2AHssIJaMOWpUydijjygaPO7IcHTAqP5NemC5WPxZa+2mVvv+8s3Zd55fna5buD7bAAzHW3NZjbfj1RJN58ihUvHLQYtW14SBI/DWAqb7Vzfi7Q+wxx9UZODIAaVV048oHlZ1ZLhiyAQTCoX7L+3e5UrxpzI2tbbJrlyyIVM3Z2X6nXXNth0YCFTiTau9CDwPrNYmmdJbVPxySKLVNUPx1gJOAyb4V7fh7RWc2f3rTUl5cdmE4ycWj5h4ZNHAkdWuNg91WfytSdv8bkP2nfnrMnXPrEy/l0hh8F5BFeM9cb4FvIq3OWazi4xS2FT80mv8YwIdCZwMHIe3HpDBWxPY6/RE0ZBxg4qGTxhVNHDU6HDlkNHhstgoE+n7A8b1V/G3pWzrpla7/oPm7LoV27LrF2/IrluxLduEtzXOYMDg/WzmAwvxdrZK7OdbihwyFb/0CX+roInANLwdxMr9TzUALfu7bX88GfRF8e+n5MEr+BjQuei9Be/YOW/gTeNoqxzpNyp+6XP+4SHGAcfgbRk0Cm9BOIQ3LdSMt7XKPnU+GYSjAweGSssrQ8XRClNcVhkqKqk0kZIKE44UH0ymnhR/MmM7EimaW5O2pSVpm5s6aN7eblvWt2Qb9lLyUbx5+s7pGwOsxCv75cBGzdmLKyp+6XfR6poKvPIfA0wGJuFNe3R9Mmjx33ZLqLSiOFw5tDJcPqgiHB1YGSqrqAyVVFSaouJSY0JhTChUnGoeXhLOZiiKNn8tc0/jBdG3Y1lLNmttNmvJZrJks5ZMa8omtrfTsjVhmzcnss3rmm3z2sZsS3OS1F7uel8lvxGoA+rxzoOwXodBllyh4pecsI8ngyF4awQhvEJN+pcO/+1BTY+MY+OHxptNzWUmteQg4xXhlXqJ/7bz1YVKXvKSil9yVpcng2F4mzgOA4bivToYhHdICcvOTUhD/tsk3hOG7XoZy6ZpVWZDotSk38ErbOPfpvNtZ6F37pfQeX0L3trEVry5+c14m69uQiUveUjFL3krWl1TjDfFUuG/rcRbQB2KNzoPd7lEhtIwarJ5P1FqUtvxnhg6L2m8NYbNePsiNHe5tGjhVQqNil9EJGBCB/4SEREpJCp+EZGAUfGLiASMil9EJGBU/CIiAaPiFxEJGBW/iEjAqPhFRAJGxS8iEjAqfhGRgFHxi4gEjIpfRCRg/j81Bbe6R4q51gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LSRQWgJuirZ",
        "colab_type": "text"
      },
      "source": [
        "## Looking at raw texts\n",
        "\n",
        "Before anything else, we can print a couple of tweets from the dataset to see how they look. Understanding the data is responsible for 80% of the success or failure in data science projects. We can use this time to observe aspects we'd like to consider when preprocessing our data.\n",
        "\n",
        "Below, we will print one random positive and one random negative tweet. We have added a color mark at the beginning of the string to further distinguish the two. (Warning: This is taken from a public dataset of real tweets and a very small portion has explicit content.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYkBOq7euBFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "79bb42d5-b455-4f66-c20b-a4e40999e5dc"
      },
      "source": [
        "# print positive in greeen\n",
        "print('\\033[92m' + all_positive_tweets[random.randint(0,5000)])\n",
        "\n",
        "# print negative in red\n",
        "print('\\033[91m' + all_negative_tweets[random.randint(0,5000)])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m@teenageblackout hi can I dm you about something? It will be quick :)\n",
            "\u001b[91m@Donoxh oh my üò¢ my friend of 8 years is helping me :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWXRVnE0uxrA",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess raw text for Sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KvgqqsOuy_g",
        "colab_type": "text"
      },
      "source": [
        "Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n",
        "\n",
        "* Tokenizing the string\n",
        "* Lowercasing\n",
        "* Removing stop words and punctuation\n",
        "* Stemming\n",
        "\n",
        "The videos explained each of these steps and why they are important. Let's see how we can do these to a given tweet. We will choose just one and see how this is transformed by each preprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFHUQ97luk8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0887a60d-204e-4811-86b7-235c0b3c74fe"
      },
      "source": [
        "# Our selected sample. Complex enough to exemplify each step\n",
        "tweet = all_positive_tweets[2277]\n",
        "print(tweet)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXYU4F8Iu83x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e62c0df7-1379-4110-eee4-cc751b5655f4"
      },
      "source": [
        "# download the stopwords from NLTK\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npWE9yTwvAq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re                                  # library for regular expression operations\n",
        "import string                              # for string operations\n",
        "\n",
        "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
        "from nltk.stem import PorterStemmer        # module for stemming\n",
        "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F8hL4rGvOZR",
        "colab_type": "text"
      },
      "source": [
        "### Remove hyperlinks,  Twitter marks and styles\n",
        "\n",
        "Since we have a Twitter dataset, we'd like to remove some substrings commonly used on the platform like the hashtag, retweet marks, and hyperlinks. We'll use the [re](https://docs.python.org/3/library/re.html) library to perform regular expression operations on our tweet. We'll define our search pattern and use the `sub()` method to remove matches by substituting with an empty character (i.e. `''`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bF2u0dDvLCb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "69ca7d5b-c949-43cc-c0cb-86d5f719ca54"
      },
      "source": [
        "print('\\033[92m' + tweet)\n",
        "print('\\033[94m')\n",
        "# remove old style retweet text \"RT\"\n",
        "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "# remove hyperlinks\n",
        "tweet2 = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet2)\n",
        "\n",
        "# remove hashtags\n",
        "# only removing the hash # sign from the word\n",
        "tweet2 = re.sub(r'#', '', tweet2)\n",
        "\n",
        "print(tweet2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92mMy beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
            "\u001b[94m\n",
            "My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off‚Ä¶ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFWrm1eav1fW",
        "colab_type": "text"
      },
      "source": [
        "### Tokenize the string\n",
        "\n",
        "To tokenize means to split the strings into individual words without blanks or tabs. In this same step, we will also convert each word in the string to lower case. The [tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual) module from NLTK allows us to do these easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsMuCMHbv6sg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "69a4dc89-3338-4b2c-f8e5-ede48d30d0a5"
      },
      "source": [
        "print()\n",
        "print('\\033[92m' + tweet2)\n",
        "print('\\033[94m')\n",
        "\n",
        "# instantiate tokenizer class\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "\n",
        "# tokenize tweets\n",
        "tweet_tokens = tokenizer.tokenize(tweet2)\n",
        "\n",
        "print()\n",
        "print('Tokenized string:')\n",
        "print(tweet_tokens)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[92mMy beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday off‚Ä¶ \n",
            "\u001b[94m\n",
            "\n",
            "Tokenized string:\n",
            "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '‚Ä¶']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJDKR3iuwEMq",
        "colab_type": "text"
      },
      "source": [
        "### Remove stop words and punctuations\n",
        "\n",
        "The next step is to remove stop words and punctuation. Stop words are words that don't add significant meaning to the text. We'll see the list provided by NLTK when you run the cells below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boGRgeMov-_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "944624b4-75d9-4a6b-a15c-08c530f720aa"
      },
      "source": [
        "#Import the english stop words list from NLTK\n",
        "stopwords_english = stopwords.words('english') \n",
        "\n",
        "#print('Stop words\\n')\n",
        "#print(stopwords_english)\n",
        "\n",
        "print('\\nPunctuation\\n')\n",
        "print(string.punctuation)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Punctuation\n",
            "\n",
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_Ax2JyIwVNS",
        "colab_type": "text"
      },
      "source": [
        "We can see that the stop words list above contains some words that could be important in some contexts. \n",
        "These could be words like _i, not, between, because, won, against_. You might need to customize the stop words list for some applications. For our exercise, we will use the entire list.\n",
        "\n",
        "For the punctuation, we saw earlier that certain groupings like ':)' and '...'  should be retained when dealing with tweets because they are used to express emotions. In other contexts, like medical analysis, these should also be removed.\n",
        "\n",
        "Time to clean up our tokenized tweet!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc3fIw5kwJhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "59970422-8172-48d7-88a9-eda7f43431fb"
      },
      "source": [
        "print()\n",
        "print('\\033[92m')\n",
        "print(tweet_tokens)\n",
        "print('\\033[94m')\n",
        "\n",
        "tweets_clean = []\n",
        "\n",
        "for word in tweet_tokens: # Go through every word in your tokens list\n",
        "    if (word not in stopwords_english and  # remove stopwords\n",
        "        word not in string.punctuation):  # remove punctuation\n",
        "        tweets_clean.append(word)\n",
        "\n",
        "print('removed stop words and punctuation:')\n",
        "print(tweets_clean)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[92m\n",
            "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', '‚Ä¶']\n",
            "\u001b[94m\n",
            "removed stop words and punctuation:\n",
            "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '‚Ä¶']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faDfLvxDwkMV",
        "colab_type": "text"
      },
      "source": [
        "### Stemming\n",
        "\n",
        "Stemming is the process of converting a word to its most general form, or stem. This helps in reducing the size of our vocabulary.\n",
        "\n",
        "Consider the words: \n",
        " * **learn**\n",
        " * **learn**ing\n",
        " * **learn**ed\n",
        " * **learn**t\n",
        " \n",
        "All these words are stemmed from its common root **learn**. However, in some cases, the stemming process produces words that are not correct spellings of the root word. For example, **happi** and **sunni**. That's because it chooses the most common stem for related words. For example, we can look at the set of words that comprises the different forms of happy:\n",
        "\n",
        " * **happ**y\n",
        " * **happi**ness\n",
        " * **happi**er\n",
        " \n",
        "We can see that the prefix **happi** is more commonly used. We cannot choose **happ** because it is the stem of unrelated words like **happen**.\n",
        " \n",
        "NLTK has different modules for stemming and we will be using the [PorterStemmer](https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter) module which uses the [Porter Stemming Algorithm](https://tartarus.org/martin/PorterStemmer/). Let's see how we can use it in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4a3_I-EwaKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3e85ab39-adb9-47bb-e25b-230cda9866be"
      },
      "source": [
        "print()\n",
        "print('\\033[92m')\n",
        "print(tweets_clean)\n",
        "print('\\033[94m')\n",
        "\n",
        "# Instantiate stemming class\n",
        "stemmer = PorterStemmer() \n",
        "\n",
        "# Create an empty list to store the stems\n",
        "tweets_stem = [] \n",
        "\n",
        "for word in tweets_clean:\n",
        "    stem_word = stemmer.stem(word)  # stemming word\n",
        "    tweets_stem.append(stem_word)  # append to the list\n",
        "\n",
        "print('stemmed words:')\n",
        "print(tweets_stem)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[92m\n",
            "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', '‚Ä¶']\n",
            "\u001b[94m\n",
            "stemmed words:\n",
            "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '‚Ä¶']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cO_vWM9hw7QA",
        "colab_type": "text"
      },
      "source": [
        "## process_tweet()\n",
        "\n",
        "As shown above, preprocessing consists of multiple steps before you arrive at the final list of words. We will not replicate these however, we will use the function `process_tweet(tweet)` which we will write combining above cells.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-D8dIHowzvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_tweet(tweet):\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "\n",
        "    \"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "    tweets_clean = []\n",
        "    tweets_clean = [stemmer.stem(word) for word in tweet_tokens if word not in stopwords_english and word not in string.punctuation]\n",
        "    #for word in tweet_tokens:\n",
        "    #    if (word not in stopwords_english and  # remove stopwords\n",
        "    #            word not in string.punctuation):  # remove punctuation\n",
        "            # tweets_clean.append(word)\n",
        "    #        stem_word = stemmer.stem(word)  # stemming word\n",
        "    #        tweets_clean.append(stem_word)\n",
        "\n",
        "    return tweets_clean\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-76lr-PqxzJR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f9f95bac-eb8a-4e7e-df12-b1caab18c211"
      },
      "source": [
        "# choose the same tweet\n",
        "tweet = all_positive_tweets[2277]\n",
        "\n",
        "print()\n",
        "print('\\033[92m')\n",
        "print(tweet)\n",
        "print('\\033[94m')\n",
        "\n",
        "# call the imported function\n",
        "tweets_stem = process_tweet(tweet); # Preprocess a given tweet\n",
        "\n",
        "print('preprocessed tweet:')\n",
        "print(tweets_stem) # Print the result"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[92m\n",
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday off‚Ä¶ https://t.co/3tfYom0N1i\n",
            "\u001b[94m\n",
            "preprocessed tweet:\n",
            "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', '‚Ä¶']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mICpfxr70FKN",
        "colab_type": "text"
      },
      "source": [
        "# Building and Visualizing word frequencies\n",
        "\n",
        "\n",
        "In the next steps, we will focus on the `build_freqs()` function and visualizing a dataset fed into it. In our goal of tweet sentiment analysis, this function will build a dictionary where we can lookup how many times a word appears in the lists of positive or negative tweets. This will be very helpful when extracting the features of the dataset for building a classifier. Let's see how this function is implemented under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhZ2ythL307G",
        "colab_type": "text"
      },
      "source": [
        "Next, we will build a labels array that matches the sentiments of our tweets.  This data type works pretty much like a regular list but is optimized for computations and manipulation. The `labels` array will be composed of 10000 elements. The first 5000 will be filled with `1` labels denoting positive sentiments, and the next 5000 will be `0` labels denoting the opposite. We can do this easily with a series of operations provided by the `numpy` library:\n",
        "\n",
        "* `np.ones()` - create an array of 1's\n",
        "* `np.zeros()` - create an array of 0's\n",
        "* `np.append()` - concatenate arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhMojNrx0ENg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a numpy array representing labels of the tweets\n",
        "labels = np.append(np.ones((len(all_positive_tweets))), np.zeros((len(all_negative_tweets))))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6neKi4636aM",
        "colab_type": "text"
      },
      "source": [
        "## Dictionaries\n",
        "\n",
        "In Python, a dictionary is a mutable and indexed collection. It stores items as key-value pairs and uses [hash tables](https://en.wikipedia.org/wiki/Hash_table) underneath to allow practically constant time lookups. In NLP, dictionaries are essential because it enables fast retrieval of items or containment checks even with thousands of entries in the collection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUCAxl_x4bFl",
        "colab_type": "text"
      },
      "source": [
        "## Word frequency dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nACG_5fF4bOL",
        "colab_type": "text"
      },
      "source": [
        "Now that we know the building blocks, let's finally create the **build_freqs()** function. This is the function that creates the dictionary containing the word counts from each corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVfxIyvM4aSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_freqs(tweets, ys):\n",
        "    \"\"\"Build frequencies.\n",
        "    Input:\n",
        "        tweets: a list of tweets\n",
        "        ys: an m x 1 array with the sentiment label of each tweet\n",
        "            (either 0 or 1)\n",
        "    Output:\n",
        "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
        "        frequency\n",
        "    \"\"\"\n",
        "    # Convert np array to list since zip needs an iterable.\n",
        "    # The squeeze is necessary or the list ends up with one element.\n",
        "    # Also note that this is just a NOP if ys is already a list.\n",
        "    yslist = np.squeeze(ys).tolist()\n",
        "\n",
        "    # Start with an empty dictionary and populate it by looping over all tweets\n",
        "    # and over all processed words in each tweet.\n",
        "    freqs = {}\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            if pair in freqs:\n",
        "                freqs[pair] += 1\n",
        "            else:\n",
        "                freqs[pair] = 1    \n",
        "    return freqs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moarkPsd5pZS",
        "colab_type": "text"
      },
      "source": [
        "We can also do the for loop like this to make it a bit more compact:\n",
        "\n",
        "```python\n",
        "    for y, tweet in zip(yslist, tweets):\n",
        "        for word in process_tweet(tweet):\n",
        "            pair = (word, y)\n",
        "            freqs[pair] = freqs.get(pair, 0) + 1\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FBeZxFr50kd",
        "colab_type": "text"
      },
      "source": [
        "Now, it is time to use the dictionary returned by the `build_freqs()` function. First, let us feed our `tweets` and `labels` lists then print a basic report:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdM-q__m3zwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f1ad0d97-b550-492b-e573-c347d9d523af"
      },
      "source": [
        "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
        "tweets = all_positive_tweets + all_negative_tweets\n",
        "\n",
        "# let's see how many tweets we have\n",
        "print(\"Number of tweets: \", len(tweets))\n",
        "# create frequency dictionary\n",
        "freqs_all = build_freqs(tweets, labels)\n",
        "\n",
        "# check data type\n",
        "print(f'type(freqs_all) = {type(freqs_all)}')\n",
        "\n",
        "# check length of the dictionary\n",
        "print(f'len(freqs_all) = {len(freqs_all)}')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets:  10000\n",
            "type(freqs_all) = <class 'dict'>\n",
            "len(freqs_all) = 13076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXjRdPDr6QJM",
        "colab_type": "text"
      },
      "source": [
        "### Table of word counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WINYaZr76sjl",
        "colab_type": "text"
      },
      "source": [
        "We will select a set of words that we would like to visualize. It is better to store this temporary information in a table that is very easy to use later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pRcA0e56rcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "a061aef9-b45e-4a48-926a-39cbe6320522"
      },
      "source": [
        "# select some words to appear in the report. we will assume that each word is unique (i.e. no duplicates)\n",
        "keys = ['happi', 'merri', 'nice', 'good', 'bad', 'sad', 'mad', 'best', 'pretti',\n",
        "        '‚ù§', ':)', ':(', 'üòí', 'üò¨', 'üòÑ', 'üòç', '‚ôõ',\n",
        "        'song', 'idea', 'power', 'play', 'magnific']\n",
        "\n",
        "# list representing our table of word counts.\n",
        "# each element consist of a sublist with this pattern: [<word>, <positive_count>, <negative_count>]\n",
        "data = []\n",
        "# loop through our selected words\n",
        "for word in keys: \n",
        "    # initialize positive and negative counts\n",
        "    pos = 0\n",
        "    neg = 0 \n",
        "    # retrieve number of positive counts\n",
        "    if (word, 1) in freqs_all:\n",
        "        pos = freqs_all[(word, 1)]     \n",
        "    # retrieve number of negative counts\n",
        "    if (word, 0) in freqs_all:\n",
        "        neg = freqs_all[(word, 0)]     \n",
        "    # append the word counts to the table\n",
        "    data.append([word, pos, neg])   \n",
        "data"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['happi', 211, 25],\n",
              " ['merri', 1, 0],\n",
              " ['nice', 98, 19],\n",
              " ['good', 238, 101],\n",
              " ['bad', 18, 73],\n",
              " ['sad', 5, 123],\n",
              " ['mad', 4, 11],\n",
              " ['best', 65, 22],\n",
              " ['pretti', 20, 15],\n",
              " ['‚ù§', 29, 21],\n",
              " [':)', 3568, 2],\n",
              " [':(', 1, 4571],\n",
              " ['üòí', 1, 3],\n",
              " ['üò¨', 0, 2],\n",
              " ['üòÑ', 5, 1],\n",
              " ['üòç', 2, 1],\n",
              " ['‚ôõ', 0, 210],\n",
              " ['song', 22, 27],\n",
              " ['idea', 26, 10],\n",
              " ['power', 7, 6],\n",
              " ['play', 46, 48],\n",
              " ['magnific', 2, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH4sNYN77DYZ",
        "colab_type": "text"
      },
      "source": [
        "We can then use a scatter plot to inspect this table visually. Instead of plotting the raw counts, we will plot it in the logarithmic scale to take into account the wide discrepancies between the raw counts (e.g. `:)` has 3568 counts in the positive while only 2 in the negative). The red line marks the boundary between positive and negative areas. Words close to the red line can be classified as neutral. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99yTl_ny63wo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "41802fbe-45b1-49ff-a8cc-611583accc94"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (8, 8))\n",
        "\n",
        "# convert positive raw counts to logarithmic scale. we add 1 to avoid log(0)\n",
        "x = np.log([x[1] + 1 for x in data])  \n",
        "# do the same for the negative counts\n",
        "y = np.log([x[2] + 1 for x in data]) \n",
        "# Plot a dot for each pair of words\n",
        "ax.scatter(x, y)  \n",
        "# assign axis labels\n",
        "plt.xlabel(\"Log Positive count\")\n",
        "plt.ylabel(\"Log Negative count\")\n",
        "# Add the word as the label at the same position as you added the points just before\n",
        "for i in range(0, len(data)):\n",
        "    ax.annotate(data[i][0], (x[i], y[i]), fontsize=12)\n",
        "\n",
        "ax.plot([0, 9], [0, 9], color = 'red') # Plot the red line that divides the 2 areas.\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128556 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128556 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHqL1cOO7clF",
        "colab_type": "text"
      },
      "source": [
        "This chart is straightforward to interpret. It shows that emoticons `:)` and `:(` are very important for sentiment analysis. Thus, we should not let preprocessing steps get rid of these symbols!\n",
        "\n",
        "Furthermore, what is the meaning of the crown symbol? It seems to be very negative!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgOCKlTc9ZL0",
        "colab_type": "text"
      },
      "source": [
        "# Visualizing tweets and the Logistic Regression model\n",
        "\n",
        "**Objectives:** Visualize and interpret the logistic regression model\n",
        "\n",
        "**Steps:**\n",
        "* Plot tweets in a scatter plot using their positive and negative sums.\n",
        "* Plot the output of the logistic regression model in the same plot as a solid line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-CRwOeE7Iwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5703cdce-810b-4682-ca17-819eee822023"
      },
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "#tweets = all_positive_tweets + all_negative_tweets ## Concatenate the lists. \n",
        "#labels = np.append(np.ones((len(all_positive_tweets),1)), np.zeros((len(all_negative_tweets),1)), axis = 0)\n",
        "\n",
        "# split the data into two pieces, one for training and one for testing (validation set) \n",
        "train_pos  = all_positive_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_neg  = all_negative_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg \n",
        "\n",
        "print(\"Number of tweets in train: \", len(train_x))\n",
        "print(\"Number of tweets in test: \", len(test_x))\n",
        "\n",
        "## Freq dictionary of training dataset\n",
        "labels_train = np.append(np.ones((len(train_pos),1)), np.zeros((len(train_neg),1)), axis = 0)\n",
        "labels_test = np.append(np.ones((len(test_pos),1)), np.zeros((len(test_neg),1)), axis = 0)\n",
        "\n",
        "freqs_train = build_freqs(train_x, labels_train)\n",
        "#freqs_test = build_freqs(test_x, labels_test)\n",
        "# check length of the dictionary\n",
        "print(f'len(freqs) for training corpus = {len(freqs_train)}')\n",
        "#print(f'len(freqs) for testing corpus = {len(freqs_test)}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets in train:  8000\n",
            "Number of tweets in test:  2000\n",
            "len(freqs) for training corpus = 11346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZHneeAv-AUQ",
        "colab_type": "text"
      },
      "source": [
        "## Numerical extracted features for training and testing\n",
        "\n",
        "Goal is the creation of the numerical features needed for the Logistic regression model.\n",
        "We will create these features created for the tweets sample. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4rOYKXm974a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(tweet, freqs):\n",
        "    '''\n",
        "    Input: \n",
        "        tweet: a list of words for one tweet\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "    Output: \n",
        "        x: a feature vector of dimension (1,3)\n",
        "    '''\n",
        "    # process_tweet tokenizes, stems, and removes stopwords\n",
        "    word_l = process_tweet(tweet)   \n",
        "    # 3 elements in the form of a 1 x 3 vector\n",
        "    x = np.zeros((1, 3))  \n",
        "    #bias term is set to 1\n",
        "    x[0,0] = 1      \n",
        "    # loop through each word in the list of words\n",
        "    for word in word_l:\n",
        "        # increment the word count for the positive label 1\n",
        "        x[0,1] += freqs.get((word,1),0)    \n",
        "        # increment the word count for the negative label 0\n",
        "        x[0,2] += freqs.get((word,0),0)\n",
        "    assert(x.shape == (1, 3))\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbsQNsglCU5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "11334372-e247-495f-8bb0-ac61ddc4e1a4"
      },
      "source": [
        "# Each feature is labeled as bias, positive and negative\n",
        "X_train = np.zeros((len(train_x), 3))\n",
        "for i in range(len(train_x)):\n",
        "    X_train[i, :]= extract_features(train_x[i], freqs_train)\n",
        "\n",
        "# training labels corresponding to X\n",
        "Y_train = labels_train\n",
        "\n",
        "X_test = np.zeros((len(test_x), 3))\n",
        "for i in range(len(test_x)):\n",
        "    X_test[i, :]= extract_features(test_x[i], freqs_train)\n",
        "\n",
        "# testing labels corresponding to X\n",
        "Y_test = labels_test\n",
        "\n",
        "print(X_train.shape) # Print the shape of the X part\n",
        "print(Y_train.shape) # Print the shape of the Y part\n",
        "print(X_test.shape) # Print the shape of the X part\n",
        "print(Y_test.shape) # Print the shape of the X part\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 3)\n",
            "(8000, 1)\n",
            "(2000, 3)\n",
            "(2000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qynGIxhDxtq",
        "colab_type": "text"
      },
      "source": [
        "## Training of Logistic Regression model\n",
        "\n",
        "We will train a Logistic regression model. The next cell contains the resulting model from such training. Notice that a list of 3 numeric values represents the whole model, that we have called _theta_ $\\theta$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuBqTuh5DDHf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "d1cb3f1b-0e59-4ee2-c9ef-6ba392a26c82"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression(random_state=0,penalty='l1',solver='liblinear',max_iter=5000).fit(X_train, Y_train)\n",
        "predictions = clf.predict(X_test)\n",
        "print(clf.score(X_train,Y_train))\n",
        "accuracy = (np.squeeze(np.asarray(predictions))==np.squeeze(Y_test)).sum()/Y_test.shape[0]\n",
        "#accuracy = np.asarray(predictions)\n",
        "#correct_predictions = 0\n",
        "#for i in range(len(predictions)):\n",
        "#  if predictions[i] == Y_test[i]:\n",
        "#    correct_predictions += 1.0\n",
        "print(\"Out of \" + str(len(predictions)) + \" test samples, our LR model is able to predict \" + str(accuracy*100) + \" precent samples correctly.\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.990375\n",
            "Out of 2000 test samples, our LR model is able to predict 99.15 precent samples correctly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYr09j7vJ2S-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta = [0.49760192,0.00903683,-0.01025924]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kG3BB_qJ_Y1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "c1db6c44-5870-4c47-fd55-6d2d066b3c4a"
      },
      "source": [
        "# Plot the samples using columns 1 and 2 of the matrix\n",
        "fig, ax = plt.subplots(figsize = (8, 8))\n",
        "\n",
        "colors = ['red', 'green']\n",
        "\n",
        "# Color based on the sentiment Y\n",
        "ax.scatter(X_train[:,1], X_train[:,2], c=[colors[int(k)] for k in Y_train], s = 0.1)  # Plot a dot for each pair of words\n",
        "plt.xlabel(\"Positive\")\n",
        "plt.ylabel(\"Negative\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Negative')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtjG1jxLVCzC",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: Logistic regression \n",
        "\n",
        "\n",
        "### Part 1.1: Sigmoid\n",
        "We will learn to use logistic regression for text classification. \n",
        "* The sigmoid function is defined as: \n",
        "\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}} \\tag{1}$$\n",
        "\n",
        "It maps the input 'z' to a value that ranges between 0 and 1, and so it can be treated as a probability. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPuye0IjVQAA",
        "colab_type": "text"
      },
      "source": [
        "#### Instructions: Implement the sigmoid function\n",
        "* We will want this function to work if z is a scalar as well as if it is an array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bDeFXiLVDJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z): \n",
        "    '''\n",
        "    Input:\n",
        "        z: is the input (can be a scalar or an array)\n",
        "    Output:\n",
        "        h: the sigmoid of z\n",
        "    '''    \n",
        "    # calculate the sigmoid of z\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    return h"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH72kejDVU0Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7f35aed2-55b5-4ab9-c60a-8772c8d02780"
      },
      "source": [
        "# Testing your function \n",
        "if (sigmoid(0) == 0.5):\n",
        "    print('SUCCESS!')\n",
        "else:\n",
        "    print('Oops!')\n",
        "\n",
        "if (sigmoid(4.92) == 0.9927537604041685):\n",
        "    print('CORRECT!')\n",
        "else:\n",
        "    print('Oops again!')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SUCCESS!\n",
            "CORRECT!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsDmtaAhVZkJ",
        "colab_type": "text"
      },
      "source": [
        "### Logistic regression: regression and a sigmoid\n",
        "\n",
        "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
        "\n",
        "Regression:\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "Note that the $\\theta$ values are \"weights\". \n",
        "\n",
        "Logistic regression\n",
        "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$\n",
        "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
        "We will refer to 'z' as the 'logits'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUVBjESsVmZW",
        "colab_type": "text"
      },
      "source": [
        "### Part 1.2 Cost function and Gradient\n",
        "\n",
        "The cost function used for logistic regression is the average of the log loss across all training examples:\n",
        "\n",
        "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
        "* $m$ is the number of training examples\n",
        "* $y^{(i)}$ is the actual label of the i-th training example.\n",
        "* $h(z(\\theta)^{(i)})$ is the model's prediction for the i-th training example.\n",
        "\n",
        "The loss function for a single training example is\n",
        "$$ Loss = -1 \\times \\left( y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)})) \\right)$$\n",
        "\n",
        "* All the $h$ values are between 0 and 1, so the logs will be negative. That is the reason for the factor of -1 applied to the sum of the two loss terms.\n",
        "* Note that when the model predicts 1 ($h(z(\\theta)) = 1$) and the label $y$ is also 1, the loss for that training example is 0. \n",
        "* Similarly, when the model predicts 0 ($h(z(\\theta)) = 0$) and the actual label is also 0, the loss for that training example is 0. \n",
        "* However, when the model prediction is close to 1 ($h(z(\\theta)) = 0.9999$) and the label is 0, the second term of the log loss becomes a large negative number, which is then multiplied by the overall factor of -1 to convert it to a positive loss value. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$ The closer the model prediction gets to 1, the larger the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g6v7M_uVjwG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b5c4de9-fe14-4b8a-dd32-c10853cad081"
      },
      "source": [
        "# verify that when the model predicts close to 1, but the actual label is 0, the loss is a large positive value\n",
        "-1 * (1 - 0) * np.log(1 - 0.9999) # loss is about 9.2"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976294"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHLSg0-NWEcV",
        "colab_type": "text"
      },
      "source": [
        "* Likewise, if the model predicts close to 0 ($h(z) = 0.0001$) but the actual label is 1, the first term in the loss function becomes a large number: $-1 \\times log(0.0001) \\approx 9.2$.  The closer the prediction is to zero, the larger the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vvob83deV9hB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a5cdbccd-f2e3-41f0-8bde-68ac11a34b02"
      },
      "source": [
        "# verify that when the model predicts close to 0 but the actual label is 1, the loss is a large positive value\n",
        "-1 * np.log(0.0001) # loss is about 9.2"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.210340371976182"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAnnTkKAWIWI",
        "colab_type": "text"
      },
      "source": [
        "#### Update the weights\n",
        "\n",
        "To update our weight vector $\\theta$, we will apply gradient descent to iteratively improve our model's predictions.  \n",
        "The gradient of the cost function $J$ with respect to one of the weights $\\theta_j$ is:\n",
        "\n",
        "$$\\nabla_{\\theta_j}J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m(h^{(i)}-y^{(i)})x_j \\tag{5}$$\n",
        "* 'i' is the index across all 'm' training examples.\n",
        "* 'j' is the index of the weight $\\theta_j$, so $x_j$ is the feature associated with weight $\\theta_j$\n",
        "\n",
        "* To update the weight $\\theta_j$, we adjust it by subtracting a fraction of the gradient determined by $\\alpha$:\n",
        "$$\\theta_j = \\theta_j - \\alpha \\times \\nabla_{\\theta_j}J(\\theta) $$\n",
        "* The learning rate $\\alpha$ is a value that we choose to control how big a single update will be.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW-sbq3YWROy",
        "colab_type": "text"
      },
      "source": [
        "## Instructions: Implement gradient descent function\n",
        "* The number of iterations `num_iters` is the number of times that you'll use the entire training set.\n",
        "* For each iteration, you'll calculate the cost function using all training examples (there are `m` training examples), and for all features.\n",
        "* Instead of updating a single weight $\\theta_i$ at a time, we can update all the weights in the column vector:  \n",
        "$$\\mathbf{\\theta} = \\begin{pmatrix}\n",
        "\\theta_0\n",
        "\\\\\n",
        "\\theta_1\n",
        "\\\\ \n",
        "\\theta_2 \n",
        "\\\\ \n",
        "\\vdots\n",
        "\\\\ \n",
        "\\theta_n\n",
        "\\end{pmatrix}$$\n",
        "* $\\mathbf{\\theta}$ has dimensions (n+1, 1), where 'n' is the number of features, and there is one more element for the bias term $\\theta_0$ (note that the corresponding feature value $\\mathbf{x_0}$ is 1).\n",
        "* The 'logits', 'z', are calculated by multiplying the feature matrix 'x' with the weight vector 'theta'.  $z = \\mathbf{x}\\mathbf{\\theta}$\n",
        "    * $\\mathbf{x}$ has dimensions (m, n+1) \n",
        "    * $\\mathbf{\\theta}$: has dimensions (n+1, 1)\n",
        "    * $\\mathbf{z}$: has dimensions (m, 1)\n",
        "* The prediction 'h', is calculated by applying the sigmoid to each element in 'z': $h(z) = sigmoid(z)$, and has dimensions (m,1).\n",
        "* The cost function $J$ is calculated by taking the dot product of the vectors 'y' and 'log(h)'.  Since both 'y' and 'h' are column vectors (m,1), transpose the vector to the left, so that matrix multiplication of a row vector with column vector performs the dot product.\n",
        "$$J = \\frac{-1}{m} \\times \\left(\\mathbf{y}^T \\cdot log(\\mathbf{h}) + \\mathbf{(1-y)}^T \\cdot log(\\mathbf{1-h}) \\right)$$\n",
        "* The update of theta is also vectorized.  Because the dimensions of $\\mathbf{x}$ are (m, n+1), and both $\\mathbf{h}$ and $\\mathbf{y}$ are (m, 1), we need to transpose the $\\mathbf{x}$ and place it on the left in order to perform matrix multiplication, which then yields the (n+1, 1) answer we need:\n",
        "$$\\mathbf{\\theta} = \\mathbf{\\theta} - \\frac{\\alpha}{m} \\times \\left( \\mathbf{x}^T \\cdot \\left( \\mathbf{h-y} \\right) \\right)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWWurSwSWF8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradientDescent(x, y, theta, alpha, num_iters):\n",
        "    '''\n",
        "    Input:\n",
        "        x: matrix of features which is (m,n+1)\n",
        "        y: corresponding labels of the input matrix x, dimensions (m,1)\n",
        "        theta: weight vector of dimension (n+1,1)\n",
        "        alpha: learning rate\n",
        "        num_iters: number of iterations you want to train your model for\n",
        "    Output:\n",
        "        J: the final cost\n",
        "        theta: your final weight vector\n",
        "    Hint: you might want to print the cost to make sure that it is going down.\n",
        "    '''\n",
        "    # get 'm', the number of rows in matrix x\n",
        "    m = x.shape[0]    \n",
        "    for i in range(0, num_iters):\n",
        "        # get z, the dot product of x and theta\n",
        "        z = np.dot(x,theta)\n",
        "        # get the sigmoid of z\n",
        "        h = sigmoid(z)\n",
        "        # calculate the cost function\n",
        "        J = -(np.dot(y.T,np.log(h)) + np.dot(((1-y).T),np.log(1-h)))*(1./m)\n",
        "        # update the weights theta\n",
        "        theta = theta - ((alpha/m) * (np.dot(x.T,(h-y))))\n",
        "    J = float(J)\n",
        "    return J, theta"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm3rgE21YWiz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "21f3b18b-9e8c-4fd9-934d-5fa98913cc9e"
      },
      "source": [
        "# Check the function\n",
        "# Construct a synthetic test case using numpy PRNG functions\n",
        "np.random.seed(1)\n",
        "# X input is 10 x 3 with ones for the bias terms\n",
        "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
        "# Y Labels are 10 x 1\n",
        "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
        "\n",
        "# Apply gradient descent\n",
        "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
        "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cost after training is 0.67094970.\n",
            "The resulting vector of weights is [4.1e-07, 0.00035658, 7.309e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7rqqxE3hQyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e578d11-05e1-4a17-8f7a-9e13a71dedb5"
      },
      "source": [
        "# test 2:\n",
        "# check for when the words are not in the freqs dictionary\n",
        "tmp2 = extract_features('blorb bleeeeb bloooob', freqs_train)\n",
        "print(tmp2)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3IjxhW2ZhoV",
        "colab_type": "text"
      },
      "source": [
        "## Part 3: Training Your Model\n",
        "\n",
        "To train the model:\n",
        "* Stack the features for all training examples into a matrix `X`. \n",
        "* Call `gradientDescent`, which we've implemented above.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx0WdqVXYYD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ffce70ec-2f68-41cb-f63b-fb4d7e941081"
      },
      "source": [
        "# Apply gradient descent\n",
        "J, theta = gradientDescent(X_train, Y_train, np.zeros((3, 1)), 1e-9, 1500)\n",
        "print(f\"The cost after training is {J:.8f}.\")\n",
        "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cost after training is 0.24216529.\n",
            "The resulting vector of weights is [7e-08, 0.0005239, -0.00055517]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwkxCIy1hihg",
        "colab_type": "text"
      },
      "source": [
        "# Part 4: Test your logistic regression\n",
        "\n",
        "It is time for us to test our logistic regression function on some new input that our model has not seen before. \n",
        "\n",
        "#### Instructions: Write `predict_tweet`\n",
        "Predict whether a tweet is positive or negative.\n",
        "\n",
        "* Given a tweet, process it, then extract the features.\n",
        "* Apply the model's learned weights on the features to get the logits.\n",
        "* Apply the sigmoid to the logits to get the prediction (a value between 0 and 1).\n",
        "\n",
        "$$y_{pred} = sigmoid(\\mathbf{x} \\cdot \\theta)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axVss-zOhhpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_tweet(tweet, freqs, theta):\n",
        "    '''\n",
        "    Input: \n",
        "        tweet: a string\n",
        "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
        "        theta: (3,1) vector of weights\n",
        "    Output: \n",
        "        y_pred: the probability of a tweet being positive or negative\n",
        "    '''\n",
        "    # extract the features of the tweet and store it into x\n",
        "    x = extract_features(tweet,freqs)\n",
        "    # make the prediction using x and theta\n",
        "    y_pred = sigmoid(np.dot(x,theta))\n",
        "    return y_pred"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05c4M85pZ5SB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4774cb10-b9b3-4e33-9fbe-e3dfe7e4c767"
      },
      "source": [
        "# Run this cell to test your function\n",
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great', 'great great great', 'great great great great']:\n",
        "    print( '%s -> %f' % (tweet, predict_tweet(tweet, freqs_train, theta)))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am happy -> 0.518580\n",
            "I am bad -> 0.494339\n",
            "this movie should have been great. -> 0.515331\n",
            "great -> 0.515464\n",
            "great great -> 0.530898\n",
            "great great great -> 0.546273\n",
            "great great great great -> 0.561561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL5rSV3Fhpuu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ec6ffa09-4aa2-401d-edc0-7ae92877ab91"
      },
      "source": [
        "# Feel free to check the sentiment of your own tweet below\n",
        "my_tweet = 'I am learning :)'\n",
        "predict_tweet(my_tweet, freqs_train, theta)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.81636424]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTaD1KBbhv5E",
        "colab_type": "text"
      },
      "source": [
        "## Check performance using the test set\n",
        "After training our model using the training set above, check how model might perform on real, unseen data, by testing it against the test set.\n",
        "\n",
        "#### Instructions: Implement `test_logistic_regression` \n",
        "* Given the test data and the weights of our trained model, calculate the accuracy of our logistic regression model. \n",
        "* Use our `predict_tweet()` function to make predictions on each tweet in the test set.\n",
        "* If the prediction is > 0.5, set the model's classification `y_hat` to 1, otherwise set the model's classification `y_hat` to 0.\n",
        "* A prediction is accurate when `y_hat` equals `test_y`.  Sum up all the instances when they are equal and divide by `m`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNOvueirhr2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        test_x: a list of tweets\n",
        "        test_y: (m, 1) vector with the corresponding labels for the list of tweets\n",
        "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
        "        theta: weight vector of dimension (3, 1)\n",
        "    Output: \n",
        "        accuracy: (# of tweets classified correctly) / (total # of tweets)\n",
        "    \"\"\"\n",
        "    # the list for storing predictions\n",
        "    y_hat = []\n",
        "    for tweet in test_x:\n",
        "        # get the label prediction for the tweet\n",
        "        y_pred = predict_tweet(tweet, freqs_train, theta)\n",
        "        if y_pred > 0.5:\n",
        "            # append 1.0 to the list\n",
        "            y_hat.append(1)\n",
        "        else:\n",
        "            # append 0 to the list\n",
        "            y_hat.append(0)\n",
        "    # With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
        "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
        "    accuracy = (np.squeeze(np.asarray(y_hat))==np.squeeze(test_y)).sum()/test_y.shape[0]\n",
        "    return accuracy"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liJoYL0nm8Oj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f8f9f3d1-648c-43ee-a1de-6506d3ffcc4f"
      },
      "source": [
        "tmp_accuracy = test_logistic_regression(test_x, labels_test, freqs_train, theta)\n",
        "print(f\"Logistic regression model's accuracy = {tmp_accuracy:.4f}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression model's accuracy = 0.9950\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIjSW9i7nKU4",
        "colab_type": "text"
      },
      "source": [
        "# Part 5: Error Analysis\n",
        "\n",
        "In this part we will see some tweets that our model misclassified. Why do you think the misclassifications happened? Specifically what kind of tweets does our model misclassify?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dWEdGuym98e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "outputId": "57285c3b-3291-4c13-d9f7-bc402a86f788"
      },
      "source": [
        "# Some error analysis done for you\n",
        "print('Label Predicted Tweet')\n",
        "for x,y in zip(test_x,labels_test):\n",
        "    y_hat = predict_tweet(x, freqs_train, theta)\n",
        "\n",
        "    if np.abs(y - (y_hat > 0.5)) > 0:\n",
        "        print('THE TWEET IS:', x)\n",
        "        print('THE PROCESSED TWEET IS:', process_tweet(x))\n",
        "        print('%d\\t%0.8f\\t%s' % (y, y_hat, ' '.join(process_tweet(x)).encode('ascii', 'ignore')))\n",
        "        print(\"\\n\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label Predicted Tweet\n",
            "THE TWEET IS: @jaredNOTsubway @iluvmariah @Bravotv Then that truly is a LATERAL move! Now, we all know the Queen Bee is UPWARD BOUND : ) #MovingOnUp\n",
            "THE PROCESSED TWEET IS: ['truli', 'later', 'move', 'know', 'queen', 'bee', 'upward', 'bound', 'movingonup']\n",
            "1\t0.49996890\tb'truli later move know queen bee upward bound movingonup'\n",
            "\n",
            "\n",
            "THE TWEET IS: @MarkBreech Not sure it would be good thing 4 my bottom daring 2 say 2 Miss B but Im gonna be so stubborn on mouth soaping ! #NotHavingit :p\n",
            "THE PROCESSED TWEET IS: ['sure', 'would', 'good', 'thing', '4', 'bottom', 'dare', '2', 'say', '2', 'miss', 'b', 'im', 'gonna', 'stubborn', 'mouth', 'soap', 'nothavingit', ':p']\n",
            "1\t0.48622857\tb'sure would good thing 4 bottom dare 2 say 2 miss b im gonna stubborn mouth soap nothavingit :p'\n",
            "\n",
            "\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots\n",
            "http://t.co/UGQzOx0huu\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48370665\tb\"i'm play brain dot braindot\"\n",
            "\n",
            "\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/aOKldo3GMj http://t.co/xWCM9qyRG5\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48370665\tb\"i'm play brain dot braindot\"\n",
            "\n",
            "\n",
            "THE TWEET IS: I'm playing Brain Dots : ) #BrainDots http://t.co/R2JBO8iNww http://t.co/ow5BBwdEMY\n",
            "THE PROCESSED TWEET IS: [\"i'm\", 'play', 'brain', 'dot', 'braindot']\n",
            "1\t0.48370665\tb\"i'm play brain dot braindot\"\n",
            "\n",
            "\n",
            "THE TWEET IS: off to the park to get some sunlight : )\n",
            "THE PROCESSED TWEET IS: ['park', 'get', 'sunlight']\n",
            "1\t0.49578765\tb'park get sunlight'\n",
            "\n",
            "\n",
            "THE TWEET IS: @msarosh Uff Itna Miss karhy thy ap :p\n",
            "THE PROCESSED TWEET IS: ['uff', 'itna', 'miss', 'karhi', 'thi', 'ap', ':p']\n",
            "1\t0.48199810\tb'uff itna miss karhi thi ap :p'\n",
            "\n",
            "\n",
            "THE TWEET IS: @phenomyoutube u probs had more fun with david than me : (\n",
            "THE PROCESSED TWEET IS: ['u', 'prob', 'fun', 'david']\n",
            "0\t0.50020353\tb'u prob fun david'\n",
            "\n",
            "\n",
            "THE TWEET IS: pats jay : (\n",
            "THE PROCESSED TWEET IS: ['pat', 'jay']\n",
            "0\t0.50039294\tb'pat jay'\n",
            "\n",
            "\n",
            "THE TWEET IS: my beloved grandmother : ( https://t.co/wt4oXq5xCf\n",
            "THE PROCESSED TWEET IS: ['belov', 'grandmoth']\n",
            "0\t0.50000002\tb'belov grandmoth'\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGn6SIg_nStw",
        "colab_type": "text"
      },
      "source": [
        "# Part 6: Predict with your own tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZJdqrPznLrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f742609f-2f0f-461f-ab16-cc1a0d110ee1"
      },
      "source": [
        "# Feel free to change the tweet below\n",
        "my_tweet = 'This is a ridiculously bright movie. The plot was terrible and I was sad until the ending!'\n",
        "print(process_tweet(my_tweet))\n",
        "y_hat = predict_tweet(my_tweet, freqs_train, theta)\n",
        "print(y_hat)\n",
        "if y_hat > 0.5:\n",
        "    print('Positive sentiment')\n",
        "else: \n",
        "    print('Negative sentiment')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ridicul', 'bright', 'movi', 'plot', 'terribl', 'sad', 'end']\n",
            "[[0.48139087]]\n",
            "Negative sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEIizo6inUIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}